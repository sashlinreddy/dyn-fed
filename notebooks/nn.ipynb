{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from fault_tolerant_ml.data.mnist import MNist\n",
    "from fault_tolerant_ml.ml import nn\n",
    "import fault_tolerant_ml.ml.nn.activation as F\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "filepaths = {\n",
    "    \"train\": {\n",
    "        \"images\": os.path.join(data_dir, \"train-images-idx3-ubyte.gz\"), \"labels\": os.path.join(data_dir, \"train-labels-idx1-ubyte.gz\")\n",
    "    },\n",
    "    \"test\": {\n",
    "        \"images\": os.path.join(data_dir, \"t10k-images-idx3-ubyte.gz\"), \"labels\": os.path.join(data_dir, \"t10k-labels-idx1-ubyte.gz\")\n",
    "    }\n",
    "}\n",
    "mnist = MNist(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MNist X_train=(60000, 784), y_train=(60000, 10), X_test=(10000, 784), y_test=(10000, 10)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features=784, n_classes=10\n"
     ]
    }
   ],
   "source": [
    "n_features, n_classes = mnist.X_train.shape[1], mnist.y_train.shape[1]\n",
    "print(f\"n_features={n_features}, n_classes={n_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.random.randn(n_features, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.fc1 = nn.Layer(n_inputs=784, n_outputs=128)\n",
    "        self.fc2 = nn.Layer(n_inputs=128, n_outputs=10)\n",
    "        \n",
    "        self.act_fn = F.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        z1 = self.fc1(x)\n",
    "        a1 = self.act_fn(z1)\n",
    "        z2 = self.fc2(a1)\n",
    "        y_pred = self.act_fn(z2)\n",
    "        \n",
    "        return y_pred, z2, a1, z1\n",
    "    \n",
    "    def backward(self, x, y, a_n):\n",
    "        \n",
    "        y_pred, z2, a1, z1 = a_n\n",
    "        # Output layer error\n",
    "        delta2 = (y_pred - y)# * self.act_fn.grad(z2)\n",
    "        # Gradient of cost function\n",
    "        dw2 = np.dot(a1.T, delta2)\n",
    "        # Backpropagate the error through the network\n",
    "        delta1 = np.dot(delta2, self.fc2.W.T) * self.act_fn.grad(z1)\n",
    "        # Calculate gradient\n",
    "        dw1 = np.dot(x.T, delta1)\n",
    "        # Gradient of biases equal to the error\n",
    "        db2 = np.sum(delta2, axis=0, keepdims=True)\n",
    "        db1 = np.sum(delta1, axis=0, keepdims=True)\n",
    "        return dw2, db2, dw1, db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_pred, y):\n",
    "    return np.mean(-y * np.log(y_pred) - (1 - y) * np.log(1 - y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_score(y, y_pred):\n",
    "    y_pred_ = y_pred.argmax(axis=1)\n",
    "    y_ = y.argmax(axis=1)\n",
    "    return np.sum(y_pred_==y_) / y_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 128)\n",
      "(128, 10)\n",
      "epoch = 0, loss = 0.691, TRAIN ACC = 0.097\n",
      "epoch = 10, loss = 0.345, TRAIN ACC = 0.112\n",
      "epoch = 20, loss = 0.342, TRAIN ACC = 0.112\n",
      "epoch = 30, loss = 0.342, TRAIN ACC = 0.112\n",
      "epoch = 40, loss = 0.341, TRAIN ACC = 0.112\n",
      "epoch = 50, loss = 0.341, TRAIN ACC = 0.112\n",
      "epoch = 60, loss = 0.341, TRAIN ACC = 0.112\n",
      "epoch = 70, loss = 0.341, TRAIN ACC = 0.114\n",
      "epoch = 80, loss = 0.340, TRAIN ACC = 0.132\n",
      "epoch = 90, loss = 0.339, TRAIN ACC = 0.160\n",
      "epoch = 100, loss = 0.339, TRAIN ACC = 0.183\n",
      "epoch = 110, loss = 0.338, TRAIN ACC = 0.200\n",
      "epoch = 120, loss = 0.337, TRAIN ACC = 0.211\n",
      "epoch = 130, loss = 0.335, TRAIN ACC = 0.219\n",
      "epoch = 140, loss = 0.333, TRAIN ACC = 0.225\n",
      "epoch = 150, loss = 0.331, TRAIN ACC = 0.228\n",
      "epoch = 160, loss = 0.327, TRAIN ACC = 0.234\n",
      "epoch = 170, loss = 0.323, TRAIN ACC = 0.243\n",
      "epoch = 180, loss = 0.318, TRAIN ACC = 0.255\n",
      "epoch = 190, loss = 0.312, TRAIN ACC = 0.272\n",
      "epoch = 200, loss = 0.306, TRAIN ACC = 0.304\n",
      "epoch = 210, loss = 0.299, TRAIN ACC = 0.358\n",
      "epoch = 220, loss = 0.293, TRAIN ACC = 0.411\n",
      "epoch = 230, loss = 0.286, TRAIN ACC = 0.456\n",
      "epoch = 240, loss = 0.280, TRAIN ACC = 0.496\n",
      "epoch = 250, loss = 0.273, TRAIN ACC = 0.530\n",
      "epoch = 260, loss = 0.267, TRAIN ACC = 0.559\n",
      "epoch = 270, loss = 0.260, TRAIN ACC = 0.581\n",
      "epoch = 280, loss = 0.254, TRAIN ACC = 0.600\n",
      "epoch = 290, loss = 0.248, TRAIN ACC = 0.617\n",
      "epoch = 300, loss = 0.241, TRAIN ACC = 0.635\n",
      "epoch = 310, loss = 0.235, TRAIN ACC = 0.652\n",
      "epoch = 320, loss = 0.230, TRAIN ACC = 0.669\n",
      "epoch = 330, loss = 0.225, TRAIN ACC = 0.684\n",
      "epoch = 340, loss = 0.220, TRAIN ACC = 0.699\n",
      "epoch = 350, loss = 0.216, TRAIN ACC = 0.713\n",
      "epoch = 360, loss = 0.211, TRAIN ACC = 0.726\n",
      "epoch = 370, loss = 0.207, TRAIN ACC = 0.739\n",
      "epoch = 380, loss = 0.204, TRAIN ACC = 0.751\n",
      "epoch = 390, loss = 0.200, TRAIN ACC = 0.762\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet()\n",
    "print(model.fc1.shape)\n",
    "print(model.fc2.shape)\n",
    "epochs = 400\n",
    "learning_rate = 0.99\n",
    "m = mnist.X_train.shape[0]\n",
    "for epoch in np.arange(epochs):\n",
    "    \n",
    "    # Feedforward\n",
    "    y_pred, z2, a1, z1 = model.forward(mnist.X_train)\n",
    "    \n",
    "    # Calculate cost\n",
    "    loss = cross_entropy_loss(y_pred, mnist.y_train)\n",
    "    \n",
    "    # Backprop\n",
    "    dw2, db2, dw1, db1 = model.backward(mnist.X_train, mnist.y_train, [y_pred, z2, a1, z1])\n",
    "    \n",
    "    # Update weights\n",
    "    model.fc2.W = model.fc2.W - learning_rate * 1 / m * dw2\n",
    "    model.fc1.W = model.fc1.W - learning_rate * 1 / m * dw1\n",
    "    model.fc2.b = model.fc2.b - learning_rate * 1 / m * db2\n",
    "    model.fc1.b = model.fc1.b - learning_rate * 1 / m * db1\n",
    "    \n",
    "    acc = accuracy_score(mnist.y_train, y_pred)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch = {epoch}, loss = {loss:.3f}, TRAIN ACC = {acc:.3f}')\n",
    "    epoch += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ftml]",
   "language": "python",
   "name": "conda-env-ftml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
